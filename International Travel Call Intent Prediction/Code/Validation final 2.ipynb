{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from pyspark.sql.functions import concat, col, lit\n",
    "\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.sql(\"select mtn,ivrcallid,start_tm_local from vzw_cja_prd_tbls.verint_call_transcripts_raw  \\\n",
    "                    where cast(end_tm_local as timestamp) BETWEEN '2019-11-23 09:00:00' AND '2019-11-24 09:00:00'\")\n",
    "\n",
    "# where day(end_tm_local)=22 AND month(end_tm_local)=11 AND year(end_tm_local)=2019\") \n",
    "\n",
    "#cast(end_tm_local as timestamp) BETWEEN '2019-11-22 09:00:00' AND '2019-11-13 09:00:00' ORDER BY START_TM_LOCAL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driverDF= spark.sql(\"SELECT ivr_id AS ivrcallid, primary_topic,secondary_topic FROM vzw_soi_prd_tbls.vzsoi_intl_calltopics_v1 where cast(START_TM_LOCAL as timestamp) BETWEEN '2019-11-23 09:00:00' AND '2019-11-24 09:00:00'\")\n",
    "                    \n",
    "                    #day(START_TM_LOCAL)=22 AND month(START_TM_LOCAL)=11 AND year(START_TM_LOCAL)=2019\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   joinDF= data.join(driverDF,on=['ivrcallid'],how='inner')\\\n",
    "                 .dropDuplicates(['ivrcallid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinDF.select(\"mtn\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=joinDF\n",
    "a.dropDuplicates(['mtn']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinDF.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_col = split(joinDF['mtn'], '-')\n",
    "joinDF = joinDF.withColumn('mtn1', split_col.getItem(0))\n",
    "joinDF = joinDF.withColumn('mtn2', split_col.getItem(1))\n",
    "joinDF = joinDF.withColumn('mtn3',split_col.getItem(2))\n",
    "topictable=joinDF.withColumn(\"mtnconcat\",concat(col(\"mtn1\"), lit(\"\"), col(\"mtn2\"),lit(\"\"),col(\"mtn3\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topictable.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predframe= spark.sql(\"select mtn as mtnconcat,label,score from vzw_soi_prd_tbls.intl_prediction where day(process_dt)=23 AND month(process_dt)=11 AND year(process_dt)=2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predframe.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValidationDF= predframe.join(topictable,on=['mtnconcat'],how='inner')\n",
    "# joinDF= data.join(driverDF,on=['ivrcallid'],how='inner')\\\n",
    " #                .dropDuplicates(['ivrcallid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValidationDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValidationDF.groupby('mtn').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= ValidationDF.dropDuplicates(['mtn'])\n",
    "a.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_conf=ValidationDF.select('label','primary_topic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(prediction_conf).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_conf = prediction_conf.withColumn('primary_topic', when((col('primary_topic') =='FRAUD')| (col('primary_topic') =='STOLEN & DAMAGED'),'PLAN & TRAVEL PASS').otherwise(col('primary_topic')))\n",
    "prediction_conf = prediction_conf.withColumn('primary_topic', when(col('primary_topic') =='PHONE SETTINGS','phone_settings').otherwise(col('primary_topic')))\n",
    "prediction_conf = prediction_conf.withColumn('primary_topic', when(col('primary_topic') =='BILLING','billing').otherwise(col('primary_topic')))\n",
    "prediction_conf = prediction_conf.withColumn('primary_topic', when(col('primary_topic') =='CRUISE','cruise').otherwise(col('primary_topic')))\n",
    "prediction_conf = prediction_conf.withColumn('primary_topic', when(col('primary_topic') =='PLAN & TRAVEL PASS','plan_travelpass').otherwise(col('primary_topic')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_conf = prediction_conf.withColumn('primary_topic', when(col('primary_topic') =='phone_settings',3.0).otherwise(col('primary_topic')))\n",
    "prediction_conf = prediction_conf.withColumn('primary_topic', when(col('primary_topic') =='billing',1.0).otherwise(col('primary_topic')))\n",
    "prediction_conf = prediction_conf.withColumn('primary_topic', when(col('primary_topic') =='cruise',2.0).otherwise(col('primary_topic')))\n",
    "prediction_conf = prediction_conf.withColumn('primary_topic', when(col('primary_topic') =='plan_travelpass',0.0).otherwise(col('primary_topic')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_conf = prediction_conf.withColumn('label', when(col('label') =='phone_settings',3.0).otherwise(col('label')))\n",
    "prediction_conf = prediction_conf.withColumn('label', when(col('label') =='billing',1.0).otherwise(col('label')))\n",
    "prediction_conf = prediction_conf.withColumn('label', when(col('label') =='cruise',2.0).otherwise(col('label')))\n",
    "prediction_conf = prediction_conf.withColumn('label', when(col('label') =='plan_travelpass',0.0).otherwise(col('label')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(prediction_conf).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=prediction_conf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(t['primary_topic'],t['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= spark.sql(\"SELECT ivr_id AS ivrcallid, primary_topic, secondary_topic,START_TM_LOCAL FROM vzw_soi_prd_tbls.vzsoi_intl_calltopics_v1 WHERE cast(START_TM_LOCAL as timestamp) BETWEEN '2019-11-16 00:00:00' AND '2019-11-22 00:00:00' ORDER BY START_TM_LOCAL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= spark.sql(\"SELECT count(ivr_id) FROM vzw_soi_prd_tbls.vzsoi_intl_calltopics_v1 WHERE cast(START_TM_LOCAL as timestamp) BETWEEN '2019-11-16 00:00:00' AND '2019-11-18 00:00:00' ORDER BY START_TM_LOCAL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "--lets do like what surya did, call 1, call 2 , call 3 for same mtn"
   ]
  }
 ],
 "metadata": {
  "kernel_args": {
   "conf": {
    "spark.driver.memoryOverhead": "24g",
    "spark.executor.memoryOverhead": "24g"
   },
   "driver-cores": "12",
   "driver-memory": "24g",
   "executor-cores": "12",
   "executor-memory": "36g",
   "num-executors": "50",
   "version": "current-2.3"
  },
  "kernelspec": {
   "display_name": "PySpark 3 (Beta)",
   "language": "",
   "name": "pysparkkernel3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark3",
   "pygments_lexer": "ipython2",
   "version": "1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}